name: Yahoo RAW batch

on:
  workflow_dispatch:
    inputs:
      tickers:
        description: "Comma-separated tickers (e.g. AAPL,MSFT,NVDA)"
        required: true
        default: "AAPL,MSFT"
      start:
        description: "Start date (YYYY-MM-DD)"
        required: false
        default: "1996-01-01"
      end:
        description: "End date (optional; blank = up to today)"
        required: false
        default: ""

jobs:
  ingest:
    runs-on: ubuntu-latest
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      SUPABASE_BUCKET: lake
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install yfinance==0.2.43 pandas==2.2.3 pyarrow==15.0.2 supabase==2.18.1 requests==2.32.3

      - name: Ingest and upload to Supabase
        run: |
          python - <<'PY'
          import os, io, time, json
          import pandas as pd
          import yfinance as yf
          from supabase import create_client

          URL  = os.environ["SUPABASE_URL"]
          KEY  = os.environ["SUPABASE_SERVICE_ROLE_KEY"]
          BUCK = os.environ.get("SUPABASE_BUCKET","lake")

          raw   = "${{ github.event.inputs.tickers }}"
          start = "${{ github.event.inputs.start }}".strip() or "1996-01-01"
          end   = "${{ github.event.inputs.end }}".strip() or None

          def ysym(t): return t.replace(".", "-").upper()
          tickers = [t.strip().upper() for t in raw.split(",") if t.strip()]
          jobs    = [{"ticker": t, "start": start, "end": end} for t in tickers]

          client = create_client(URL, KEY)
          store  = client.storage.from_(BUCK)

          SCHEMA = ["date","Ticker","Open","High","Low","Close","Adj Close","Volume","Dividends","Stock Splits"]

          def dl_raw(tkr, s, e, tries=4, pause=4):
              last = None
              for i in range(tries):
                  try:
                      df = yf.download(ysym(tkr), start=s, end=e, actions=True,
                                       auto_adjust=False, progress=False, threads=False)
                      if df is None or df.empty:
                          raise RuntimeError("empty")
                      if isinstance(df.columns, pd.MultiIndex):
                          df = df.droplevel(1, axis=1)
                      out = pd.DataFrame(index=range(len(df)))
                      out["date"]        = pd.to_datetime(df.index).tz_localize(None)
                      out["Ticker"]      = tkr.upper()
                      out["Open"]        = df.get("Open", pd.NA)
                      out["High"]        = df.get("High", pd.NA)
                      out["Low"]         = df.get("Low", pd.NA)
                      out["Close"]       = df.get("Close", pd.NA)
                      out["Adj Close"]   = df.get("Adj Close", pd.NA)
                      out["Volume"]      = df.get("Volume", pd.NA)
                      out["Dividends"]   = df.get("Dividends", 0.0 if "Dividends" in df else 0.0)
                      out["Stock Splits"]= df.get("Stock Splits", 0.0 if "Stock Splits" in df else 0.0)
                      return out[SCHEMA].sort_values("date")
                  except Exception as e:
                      last = e
                      time.sleep(pause)
              raise last

          results = []
          ok = failed = 0
          for j in jobs:
              t = j["ticker"]; print(f"Fetching {t} …", flush=True)
              try:
                  d = dl_raw(t, j["start"], j["end"])
                  buf = io.BytesIO()
                  d.to_parquet(buf, index=False, compression="snappy")
                  dest = f"prices/{t}.parquet"
                  store.upload(dest, buf.getvalue(), {"contentType":"application/octet-stream","upsert":True})
                  print(f"Uploaded {dest} rows={len(d)} range=[{d['date'].min().date()} → {d['date'].max().date()}]", flush=True)
                  results.append({"ticker": t, "error": None, "rows": int(len(d)), "path": dest})
                  ok += 1
              except Exception as e:
                  print(f"{t}: ERROR {e}", flush=True)
                  results.append({"ticker": t, "error": str(e)})
                  failed += 1

          summary = {"ok": ok, "failed": failed, "results": results}
          print(json.dumps(summary, indent=2))
          if ok == 0:
              raise SystemExit("All jobs failed")
          PY
